{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "placement2.ipynb",
      "provenance": [],
      "mount_file_id": "1tOzSvpSIaLeMhTx3TDbCoVH2pxVsMTFk",
      "authorship_tag": "ABX9TyNa67GhhVx4vLZmNeRy8jTH"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7If8e1Z-t7S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d45c2918-9b81-4b3d-9116-fd8a42ebeb07"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten,Conv1D,Activation,BatchNormalization,Dropout\n",
        "import numpy as  np\n",
        "import pandas as pd\n",
        "\n",
        "data=pd.read_csv('/content/drive/My Drive/data_deep_learning/placement_dataset.csv')\n",
        "#x=data.drop(['sl_no','status','salary'],axis=1)\n",
        "#y=data['status']\n",
        "#x.head()\n",
        "#x.shape,y.shape\n",
        "\n",
        "\n",
        "#from sklearn.preprocessing import LabelEncoder\n",
        "#label1=LabelEncoder()\n",
        "#X['Geography']=label1.fit_transform(X['Geography'])\n",
        "#label2=LabelEncoder()\n",
        "#X['Gender']=label2.fit_transform(X['Gender'])\n",
        "##print(X)\n",
        "#class_name=['not exited','Exited']\n",
        "#X=pd.get_dummies(X,drop_first=True,columns=['Geography'])\n",
        "#print(X)\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label1=LabelEncoder()\n",
        "data['gender']=label1.fit_transform(data['gender'])\n",
        "#x.head()\n",
        "label2=LabelEncoder()\n",
        "data['ssc_b']=label2.fit_transform(data['ssc_b'])\n",
        "#x.head()\n",
        "#print(x['ssc_b'])\n",
        "#x['ssc_b'].value_counts()\n",
        "label3=LabelEncoder()\n",
        "data['hsc_b']=label3.fit_transform(data['hsc_b'])\n",
        "#x.head()\n",
        "#x['hsc_b'].value_counts()\n",
        "label4=LabelEncoder()\n",
        "data['hsc_s']=label4.fit_transform(data['hsc_s'])\n",
        "#x.head()\n",
        "data=pd.get_dummies(data,drop_first=True,columns=['hsc_s'])\n",
        "#x.head()\n",
        "label5=LabelEncoder()\n",
        "data['degree_t']=label5.fit_transform(data['degree_t'])\n",
        "#x.head()\n",
        "data=pd.get_dummies(data,drop_first=True,columns=['degree_t'])\n",
        "#x.head()\n",
        "label6=LabelEncoder()\n",
        "data['workex']=label6.fit_transform(data['workex'])\n",
        "#x.head()\n",
        "label7=LabelEncoder()\n",
        "data['specialisation']=label7.fit_transform(data['specialisation'])\n",
        "label8=LabelEncoder()\n",
        "data['status']=label8.fit_transform(data['status'])\n",
        "#print(y)\n",
        "x=data.drop(['sl_no','status','salary'],axis=1)\n",
        "y=data['status']\n",
        "x.head()\n",
        "#x['specialisation'].value_counts()\n",
        "y.head()\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scale=StandardScaler()\n",
        "x_train=scale.fit_transform(x_train)\n",
        "x_test=scale.transform(x_test)\n",
        "\n",
        "print(x_train.shape,x_test.shape)\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(optimizer='adam',loss=tf.keras.losses.BinaryCrossentropy(),metrics=['accuracy'])\n",
        "model.fit(x_train,y_train,epochs=90)\n",
        "\n",
        "prediction=model.predict_classes(x_test)\n",
        "print(y_test)\n",
        "#np.set_printoptions(suppress=True)\n",
        "print(prediction)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(193, 14) (22, 14)\n",
            "Epoch 1/90\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.6038 - accuracy: 0.7409\n",
            "Epoch 2/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.8394\n",
            "Epoch 3/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8705\n",
            "Epoch 4/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8808\n",
            "Epoch 5/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.8912\n",
            "Epoch 6/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.8964\n",
            "Epoch 7/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.2722 - accuracy: 0.9016\n",
            "Epoch 8/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.9119\n",
            "Epoch 9/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9223\n",
            "Epoch 10/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.2213 - accuracy: 0.9275\n",
            "Epoch 11/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9326\n",
            "Epoch 12/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9430\n",
            "Epoch 13/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.9482\n",
            "Epoch 14/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1807 - accuracy: 0.9430\n",
            "Epoch 15/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1715 - accuracy: 0.9430\n",
            "Epoch 16/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1634 - accuracy: 0.9430\n",
            "Epoch 17/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1578 - accuracy: 0.9430\n",
            "Epoch 18/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1528 - accuracy: 0.9534\n",
            "Epoch 19/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9482\n",
            "Epoch 20/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.9482\n",
            "Epoch 21/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1372 - accuracy: 0.9482\n",
            "Epoch 22/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9585\n",
            "Epoch 23/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9585\n",
            "Epoch 24/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1230 - accuracy: 0.9430\n",
            "Epoch 25/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9482\n",
            "Epoch 26/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.9534\n",
            "Epoch 27/90\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.1095 - accuracy: 0.9585\n",
            "Epoch 28/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1118 - accuracy: 0.9534\n",
            "Epoch 29/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1128 - accuracy: 0.9585\n",
            "Epoch 30/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1119 - accuracy: 0.9585\n",
            "Epoch 31/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.9534\n",
            "Epoch 32/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1127 - accuracy: 0.9534\n",
            "Epoch 33/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1056 - accuracy: 0.9585\n",
            "Epoch 34/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.9637\n",
            "Epoch 35/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1167 - accuracy: 0.9482\n",
            "Epoch 36/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1074 - accuracy: 0.9534\n",
            "Epoch 37/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0969 - accuracy: 0.9585\n",
            "Epoch 38/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.9585\n",
            "Epoch 39/90\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 0.9637\n",
            "Epoch 40/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0798 - accuracy: 0.9637\n",
            "Epoch 41/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.9637\n",
            "Epoch 42/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9793\n",
            "Epoch 43/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 0.9793\n",
            "Epoch 44/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9741\n",
            "Epoch 45/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.9741\n",
            "Epoch 46/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0645 - accuracy: 0.9741\n",
            "Epoch 47/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.9741\n",
            "Epoch 48/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0606 - accuracy: 0.9793\n",
            "Epoch 49/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.9793\n",
            "Epoch 50/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9793\n",
            "Epoch 51/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9845\n",
            "Epoch 52/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 0.9845\n",
            "Epoch 53/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.9482\n",
            "Epoch 54/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1113 - accuracy: 0.9585\n",
            "Epoch 55/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0868 - accuracy: 0.9689\n",
            "Epoch 56/90\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.9793\n",
            "Epoch 57/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.9845\n",
            "Epoch 58/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0582 - accuracy: 0.9896\n",
            "Epoch 59/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.9896\n",
            "Epoch 60/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9845\n",
            "Epoch 61/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9845\n",
            "Epoch 62/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9845\n",
            "Epoch 63/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9845\n",
            "Epoch 64/90\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9896\n",
            "Epoch 65/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.9845\n",
            "Epoch 66/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9845\n",
            "Epoch 67/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0440 - accuracy: 0.9896\n",
            "Epoch 68/90\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0438 - accuracy: 0.9845\n",
            "Epoch 69/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9896\n",
            "Epoch 70/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9896\n",
            "Epoch 71/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.9896\n",
            "Epoch 72/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.9845\n",
            "Epoch 73/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9896\n",
            "Epoch 74/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 0.9896\n",
            "Epoch 75/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0604 - accuracy: 0.9741\n",
            "Epoch 76/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9689\n",
            "Epoch 77/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 0.9689\n",
            "Epoch 78/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9741\n",
            "Epoch 79/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 0.9741\n",
            "Epoch 80/90\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0502 - accuracy: 0.9793\n",
            "Epoch 81/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.9793\n",
            "Epoch 82/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.9793\n",
            "Epoch 83/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 0.9845\n",
            "Epoch 84/90\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9845\n",
            "Epoch 85/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9896\n",
            "Epoch 86/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9896\n",
            "Epoch 87/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9896\n",
            "Epoch 88/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9896\n",
            "Epoch 89/90\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 0.9896\n",
            "Epoch 90/90\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 0.9896\n",
            "WARNING:tensorflow:From <ipython-input-3-e9ea5849605a>:82: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "148    1\n",
            "100    0\n",
            "153    1\n",
            "62     1\n",
            "98     1\n",
            "26     1\n",
            "33     1\n",
            "41     0\n",
            "74     1\n",
            "81     1\n",
            "123    1\n",
            "133    1\n",
            "65     0\n",
            "113    1\n",
            "104    1\n",
            "83     1\n",
            "158    0\n",
            "178    1\n",
            "189    0\n",
            "183    1\n",
            "130    0\n",
            "79     0\n",
            "Name: status, dtype: int64\n",
            "[[1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}